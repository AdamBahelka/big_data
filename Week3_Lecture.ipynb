{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import time\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update this example with air quality from Madrid.\n",
    "# Motivation for HDF5 by comparing with Numpy\n",
    "# example with numpy\n",
    "import numpy as np\n",
    "import datetime\n",
    "temperature = np.random.random(1024)\n",
    "station =15\n",
    "start_time = 1669100000 #unix time in seconds\n",
    "dt = 10 #in seconds\n",
    "\n",
    "np.savez('weather',data=temperature,start_time=start_time,station=station,frequency=dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = np.load('weather.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data', 'start_time', 'station', 'frequency']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(out.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.6748173 , 0.30240691, 0.92504552, ..., 0.69201875, 0.00400845,\n",
       "       0.17074045])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out['data']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating HDF5 Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creates new hdf5 file in the write mode overwriting if the file already exists\n",
    "f = h5py.File('big_data.h5','w')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] Unable to open file (unable to open file: name = 'big_data.hdf5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [7], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# open an existing file in the read mode, error if file does not exist\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m f \u001b[39m=\u001b[39m h5py\u001b[39m.\u001b[39;49mFile(\u001b[39m'\u001b[39;49m\u001b[39mbig_data.hdf5\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m      3\u001b[0m f\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[1;32mc:\\Users\\abahe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\h5py\\_hl\\files.py:533\u001b[0m, in \u001b[0;36mFile.__init__\u001b[1;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, alignment_threshold, alignment_interval, **kwds)\u001b[0m\n\u001b[0;32m    525\u001b[0m     fapl \u001b[39m=\u001b[39m make_fapl(driver, libver, rdcc_nslots, rdcc_nbytes, rdcc_w0,\n\u001b[0;32m    526\u001b[0m                      locking, page_buf_size, min_meta_keep, min_raw_keep,\n\u001b[0;32m    527\u001b[0m                      alignment_threshold\u001b[39m=\u001b[39malignment_threshold,\n\u001b[0;32m    528\u001b[0m                      alignment_interval\u001b[39m=\u001b[39malignment_interval,\n\u001b[0;32m    529\u001b[0m                      \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    530\u001b[0m     fcpl \u001b[39m=\u001b[39m make_fcpl(track_order\u001b[39m=\u001b[39mtrack_order, fs_strategy\u001b[39m=\u001b[39mfs_strategy,\n\u001b[0;32m    531\u001b[0m                      fs_persist\u001b[39m=\u001b[39mfs_persist, fs_threshold\u001b[39m=\u001b[39mfs_threshold,\n\u001b[0;32m    532\u001b[0m                      fs_page_size\u001b[39m=\u001b[39mfs_page_size)\n\u001b[1;32m--> 533\u001b[0m     fid \u001b[39m=\u001b[39m make_fid(name, mode, userblock_size, fapl, fcpl, swmr\u001b[39m=\u001b[39;49mswmr)\n\u001b[0;32m    535\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(libver, \u001b[39mtuple\u001b[39m):\n\u001b[0;32m    536\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_libver \u001b[39m=\u001b[39m libver\n",
      "File \u001b[1;32mc:\\Users\\abahe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\h5py\\_hl\\files.py:226\u001b[0m, in \u001b[0;36mmake_fid\u001b[1;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[0;32m    224\u001b[0m     \u001b[39mif\u001b[39;00m swmr \u001b[39mand\u001b[39;00m swmr_support:\n\u001b[0;32m    225\u001b[0m         flags \u001b[39m|\u001b[39m\u001b[39m=\u001b[39m h5f\u001b[39m.\u001b[39mACC_SWMR_READ\n\u001b[1;32m--> 226\u001b[0m     fid \u001b[39m=\u001b[39m h5f\u001b[39m.\u001b[39;49mopen(name, flags, fapl\u001b[39m=\u001b[39;49mfapl)\n\u001b[0;32m    227\u001b[0m \u001b[39melif\u001b[39;00m mode \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mr+\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m    228\u001b[0m     fid \u001b[39m=\u001b[39m h5f\u001b[39m.\u001b[39mopen(name, h5f\u001b[39m.\u001b[39mACC_RDWR, fapl\u001b[39m=\u001b[39mfapl)\n",
      "File \u001b[1;32mh5py\\_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mh5py\\_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mh5py\\h5f.pyx:106\u001b[0m, in \u001b[0;36mh5py.h5f.open\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] Unable to open file (unable to open file: name = 'big_data.hdf5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "# open an existing file in the read mode, error if file does not exist\n",
    "f = h5py.File('big_data.hdf5')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open an existing file in the read and write mode\n",
    "f = h5py.File('big_data.h5','r+') #default mode is read mode\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open an existing file in the read and write mode. If the file does not exits it will first create it!\n",
    "f = h5py.File('big_data2.hdf5','a')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('big_data.hdf5','w') as f:\n",
    "    f.write('Hello')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HDF5 Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<HDF5 dataset \"dataset1\": shape (100, 100), type \"<f8\">"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = h5py.File('big_data.h5','r+')\n",
    "np_arr = np.random.random((100,100))\n",
    "f.create_dataset('dataset1',data=np_arr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where is the numpy array ```np_arr```?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<HDF5 file \"big_data.h5\" (mode r+)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<HDF5 dataset \"dataset1\": shape (100, 100), type \"<f8\">"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f['dataset1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset1 = f['dataset1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 100)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dset1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('<f8')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data type is inherited from numpy array float64 (a.k.a <f8)\n",
    "dset1.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_arr.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.25288079, 0.03691909, 0.54506046, ..., 0.26312733, 0.13821613,\n",
       "        0.39636085],\n",
       "       [0.10899647, 0.29659176, 0.20539434, ..., 0.54614031, 0.88923355,\n",
       "        0.86662054],\n",
       "       [0.48943253, 0.54981945, 0.69585297, ..., 0.73082061, 0.77340327,\n",
       "        0.02595559],\n",
       "       ...,\n",
       "       [0.10987585, 0.00787696, 0.99706144, ..., 0.44676023, 0.72863452,\n",
       "        0.38570012],\n",
       "       [0.64983059, 0.8729022 , 0.17447264, ..., 0.57917194, 0.48564616,\n",
       "        0.81835254],\n",
       "       [0.34862517, 0.29879997, 0.48151847, ..., 0.96570328, 0.33159829,\n",
       "        0.93720287]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#how do we see the content? By slicing\n",
    "dset1[:,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Differences with the numpy arrays: The data lives in the storage and only the sliced data is brought to the memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we create a 100,100 dataframe of floats. By default, it is filled with 0 of type float32 (a.k.a <f4)\n",
    "f.create_dataset('dataset2',(100,100))\n",
    "dset2 = f['dataset2']\n",
    "dset2[:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.3, 2.3, 2.3, ..., 2.3, 2.3, 2.3],\n",
       "       [2.3, 2.3, 2.3, ..., 2.3, 2.3, 2.3],\n",
       "       [2.3, 2.3, 2.3, ..., 2.3, 2.3, 2.3],\n",
       "       ...,\n",
       "       [2.3, 2.3, 2.3, ..., 2.3, 2.3, 2.3],\n",
       "       [2.3, 2.3, 2.3, ..., 2.3, 2.3, 2.3],\n",
       "       [2.3, 2.3, 2.3, ..., 2.3, 2.3, 2.3]], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we create a 100,100 dataframe of floats filled with 2.3.\n",
    "f.create_dataset('dataset3',(100,100),fillvalue=2.3)\n",
    "dset3 = f['dataset3']\n",
    "dset3[:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<HDF5 dataset \"dataset4\": shape (10, 10), type \"<f8\">"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#another way of creating datasets in hdf file\n",
    "f.create_dataset('dataset4',data=np.random.random((10,10)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KeysViewHDF5 ['dataset1', 'dataset2', 'dataset3', 'dataset4']>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#summary: what has been done so far? we can see the datasets that are created\n",
    "f.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Difference with numpy arrays: We can create empty HDF5 datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<HDF5 dataset \"empty_dataset\": shape None, type \"|u1\">"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#empty dataset. observe that the file size does not change.\n",
    "f.create_dataset('empty_dataset',dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Empty datasets cannot be sliced",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [27], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m f[\u001b[39m'\u001b[39;49m\u001b[39mempty_dataset\u001b[39;49m\u001b[39m'\u001b[39;49m][:,:]\n",
      "File \u001b[1;32mh5py\\_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mh5py\\_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\abahe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\h5py\\_hl\\dataset.py:750\u001b[0m, in \u001b[0;36mDataset.__getitem__\u001b[1;34m(self, args, new_dtype)\u001b[0m\n\u001b[0;32m    748\u001b[0m     \u001b[39mif\u001b[39;00m args \u001b[39m==\u001b[39m () \u001b[39mor\u001b[39;00m (\u001b[39mlen\u001b[39m(args) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39mand\u001b[39;00m args[\u001b[39m0\u001b[39m] \u001b[39mis\u001b[39;00m \u001b[39mEllipsis\u001b[39m):\n\u001b[0;32m    749\u001b[0m         \u001b[39mreturn\u001b[39;00m Empty(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdtype)\n\u001b[1;32m--> 750\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mEmpty datasets cannot be sliced\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    752\u001b[0m \u001b[39m# Sort field names from the rest of the args.\u001b[39;00m\n\u001b[0;32m    753\u001b[0m names \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39m(x \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m args \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(x, \u001b[39mstr\u001b[39m))\n",
      "\u001b[1;31mValueError\u001b[0m: Empty datasets cannot be sliced"
     ]
    }
   ],
   "source": [
    "f['empty_dataset'][:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Unable to create link (name already exists)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [28], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m f[\u001b[39m'\u001b[39;49m\u001b[39mempty_dataset\u001b[39;49m\u001b[39m'\u001b[39;49m] \u001b[39m=\u001b[39m \u001b[39m42\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\abahe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\h5py\\_hl\\group.py:456\u001b[0m, in \u001b[0;36mGroup.__setitem__\u001b[1;34m(self, name, obj)\u001b[0m\n\u001b[0;32m    454\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    455\u001b[0m     ds \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcreate_dataset(\u001b[39mNone\u001b[39;00m, data\u001b[39m=\u001b[39mobj)\n\u001b[1;32m--> 456\u001b[0m     h5o\u001b[39m.\u001b[39;49mlink(ds\u001b[39m.\u001b[39;49mid, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mid, name, lcpl\u001b[39m=\u001b[39;49mlcpl)\n",
      "File \u001b[1;32mh5py\\_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mh5py\\_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mh5py\\h5o.pyx:202\u001b[0m, in \u001b[0;36mh5py.h5o.link\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: Unable to create link (name already exists)"
     ]
    }
   ],
   "source": [
    "f['empty_dataset'] = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.22233370e-311, 1.22226958e-311],\n",
       "       [4.36754031e-321, 1.35807731e-312]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#numpy arrays are not really empty.\n",
    "np.empty((2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "t1 = time.time()\n",
    "arr = np.zeros((1000,1000))\n",
    "t2 = time.time()\n",
    "print(t2-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "#np.empty is simply the fastest way of initializing an array of certain size. But it is not really empty.\n",
    "t1 = time.time()\n",
    "arr = np.empty((1000,1000))\n",
    "t2 = time.time()\n",
    "print(t2-t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexing and Slicing of HDF5 Datasets\n",
    "\n",
    "Slicing and indexing of HDF5 datasets are similar to numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.03691909, 0.54506046, 0.63388669, 0.27092217],\n",
       "       [0.29659176, 0.20539434, 0.28071654, 0.2342386 ],\n",
       "       [0.54981945, 0.69585297, 0.52450474, 0.39928347],\n",
       "       [0.22715108, 0.13081968, 0.12397939, 0.85400469],\n",
       "       [0.35287768, 0.74717552, 0.91609854, 0.95002601]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#partial output\n",
    "partial_out = dset1[:5,1:5]\n",
    "partial_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dset2[:10,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.48280023]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.97540802, 0.93148953, 0.50447757, 0.53335381, 0.74150548,\n",
       "       0.91295566, 0.91903894, 0.57625104, 0.70802657, 0.77945721,\n",
       "       0.9561224 , 0.81550761, 0.6186489 , 0.88521464, 0.72131619,\n",
       "       0.50155858, 0.55450777, 0.72853309, 0.98393849, 0.99780505,\n",
       "       0.69440188, 0.65358388, 0.95619076, 0.64748424, 0.64758228,\n",
       "       0.51289418, 0.98653657, 0.73384441, 0.88286531, 0.76949916,\n",
       "       0.86968889, 0.94772043, 0.66583016, 0.64164462, 0.99570757,\n",
       "       0.6488536 , 0.87180646, 0.95895354, 0.75093306, 0.68156174,\n",
       "       0.65702353, 0.76860118, 0.81733747, 0.698754  , 0.64236254,\n",
       "       0.99429058, 0.64962797])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#boolean indexing\n",
    "t = np.random.random(1)\n",
    "dset4 = f['dataset4']\n",
    "print(t)\n",
    "dset4[dset4>t]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Broadcasting\n",
    "\n",
    "Braodcasting works for HDF5 datasets as well and it is (almost) same as numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'Dataset' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [35], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m dset4 \u001b[39m+\u001b[39;49m\u001b[39m2\u001b[39;49m\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'Dataset' and 'int'"
     ]
    }
   ],
   "source": [
    "Â£dset4 +2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.18980807, 2.23282748, 2.20877485, 2.97540802, 2.93148953,\n",
       "        2.05760374, 2.50447757, 2.10763068, 2.05634658, 2.53335381],\n",
       "       [2.74150548, 2.07373344, 2.06436458, 2.91295566, 2.91903894,\n",
       "        2.57625104, 2.04666196, 2.70802657, 2.77945721, 2.9561224 ],\n",
       "       [2.81550761, 2.6186489 , 2.33761999, 2.05159611, 2.23645219,\n",
       "        2.24552389, 2.88521464, 2.72131619, 2.50155858, 2.55450777],\n",
       "       [2.04154207, 2.2123209 , 2.26443133, 2.36577835, 2.05748413,\n",
       "        2.0605134 , 2.72853309, 2.98393849, 2.00239295, 2.46806673],\n",
       "       [2.45282216, 2.99780505, 2.04420173, 2.69440188, 2.20159721,\n",
       "        2.65358388, 2.35458005, 2.95619076, 2.64748424, 2.08095916],\n",
       "       [2.15041676, 2.64758228, 2.01461796, 2.34526097, 2.51289418,\n",
       "        2.98653657, 2.73384441, 2.88286531, 2.12858377, 2.23413496],\n",
       "       [2.41785093, 2.05997907, 2.47176288, 2.76949916, 2.18538542,\n",
       "        2.03370401, 2.86968889, 2.14176148, 2.12422623, 2.24280815],\n",
       "       [2.94772043, 2.66583016, 2.64164462, 2.06403491, 2.99570757,\n",
       "        2.6488536 , 2.4358698 , 2.14887211, 2.08558388, 2.26691706],\n",
       "       [2.87180646, 2.95895354, 2.14105691, 2.75093306, 2.18080753,\n",
       "        2.1040185 , 2.68156174, 2.65702353, 2.76860118, 2.81733747],\n",
       "       [2.06997889, 2.24882955, 2.39691671, 2.16970679, 2.698754  ,\n",
       "        2.64236254, 2.99429058, 2.64962797, 2.16868008, 2.23843388]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dset4 has sahape (10,10)\n",
    "dset4+np.array(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.18980807, 2.23282748, 2.20877485, 2.97540802, 2.93148953,\n",
       "        2.05760374, 2.50447757, 2.10763068, 2.05634658, 2.53335381],\n",
       "       [2.74150548, 2.07373344, 2.06436458, 2.91295566, 2.91903894,\n",
       "        2.57625104, 2.04666196, 2.70802657, 2.77945721, 2.9561224 ],\n",
       "       [2.81550761, 2.6186489 , 2.33761999, 2.05159611, 2.23645219,\n",
       "        2.24552389, 2.88521464, 2.72131619, 2.50155858, 2.55450777],\n",
       "       [2.04154207, 2.2123209 , 2.26443133, 2.36577835, 2.05748413,\n",
       "        2.0605134 , 2.72853309, 2.98393849, 2.00239295, 2.46806673],\n",
       "       [2.45282216, 2.99780505, 2.04420173, 2.69440188, 2.20159721,\n",
       "        2.65358388, 2.35458005, 2.95619076, 2.64748424, 2.08095916],\n",
       "       [2.15041676, 2.64758228, 2.01461796, 2.34526097, 2.51289418,\n",
       "        2.98653657, 2.73384441, 2.88286531, 2.12858377, 2.23413496],\n",
       "       [2.41785093, 2.05997907, 2.47176288, 2.76949916, 2.18538542,\n",
       "        2.03370401, 2.86968889, 2.14176148, 2.12422623, 2.24280815],\n",
       "       [2.94772043, 2.66583016, 2.64164462, 2.06403491, 2.99570757,\n",
       "        2.6488536 , 2.4358698 , 2.14887211, 2.08558388, 2.26691706],\n",
       "       [2.87180646, 2.95895354, 2.14105691, 2.75093306, 2.18080753,\n",
       "        2.1040185 , 2.68156174, 2.65702353, 2.76860118, 2.81733747],\n",
       "       [2.06997889, 2.24882955, 2.39691671, 2.16970679, 2.698754  ,\n",
       "        2.64236254, 2.99429058, 2.64962797, 2.16868008, 2.23843388]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dset4[:,:] +2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.create_dataset('dataset5',shape=(50,50,3),data=np.random.randint(-5,5,7500))\n",
    "dset5 = f['dataset5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-2.29448105,  4.95810782, -4.32991346],\n",
       "        [-2.91430082,  2.08657161, -1.63224746],\n",
       "        [ 1.31705756,  3.22822767, -1.16125999],\n",
       "        ...,\n",
       "        [-3.12930507, -4.1337993 ,  1.00689122],\n",
       "        [-1.07447335,  4.70881822, -0.8283249 ],\n",
       "        [ 0.78527712, -4.80220851,  2.45937394]],\n",
       "\n",
       "       [[ 2.70551895, -4.04189218, -3.32991346],\n",
       "        [ 1.08569918,  3.08657161, -2.63224746],\n",
       "        [ 4.31705756, -0.77177233, -1.16125999],\n",
       "        ...,\n",
       "        [ 1.87069493, -2.1337993 ,  4.00689122],\n",
       "        [ 0.92552665,  2.70881822, -0.8283249 ],\n",
       "        [-0.21472288, -3.80220851, -3.54062606]],\n",
       "\n",
       "       [[ 4.70551895,  3.95810782,  4.67008654],\n",
       "        [-0.91430082,  2.08657161, -0.63224746],\n",
       "        [ 0.31705756,  2.22822767, -2.16125999],\n",
       "        ...,\n",
       "        [ 4.87069493,  1.8662007 ,  3.00689122],\n",
       "        [ 1.92552665,  3.70881822, -4.8283249 ],\n",
       "        [-3.21472288, -2.80220851, -4.54062606]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-0.29448105, -3.04189218,  3.67008654],\n",
       "        [ 0.08569918,  1.08657161, -3.63224746],\n",
       "        [ 2.31705756,  4.22822767, -3.16125999],\n",
       "        ...,\n",
       "        [ 1.87069493, -4.1337993 , -1.99310878],\n",
       "        [-1.07447335, -1.29118178,  0.1716751 ],\n",
       "        [-2.21472288,  2.19779149,  3.45937394]],\n",
       "\n",
       "       [[-1.29448105, -2.04189218, -0.32991346],\n",
       "        [-3.91430082,  0.08657161, -1.63224746],\n",
       "        [ 1.31705756, -1.77177233, -1.16125999],\n",
       "        ...,\n",
       "        [-2.12930507,  1.8662007 , -3.99310878],\n",
       "        [-3.07447335,  3.70881822,  3.1716751 ],\n",
       "        [ 3.78527712,  3.19779149, -4.54062606]],\n",
       "\n",
       "       [[-4.29448105,  3.95810782, -2.32991346],\n",
       "        [ 4.08569918, -3.91342839, -1.63224746],\n",
       "        [ 4.31705756, -1.77177233,  3.83874001],\n",
       "        ...,\n",
       "        [-3.12930507, -4.1337993 ,  3.00689122],\n",
       "        [ 0.92552665, -2.29118178,  3.1716751 ],\n",
       "        [-3.21472288, -4.80220851,  3.45937394]]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dset5 + np.random.random((50,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-2.99124727,  4.05576823, -4.9765106 ],\n",
       "        [-2.99124727,  2.05576823, -1.9765106 ],\n",
       "        [ 1.00875273,  3.05576823, -1.9765106 ],\n",
       "        ...,\n",
       "        [-3.99124727, -4.94423177,  1.0234894 ],\n",
       "        [-1.99124727,  4.05576823, -0.9765106 ],\n",
       "        [ 0.00875273, -4.94423177,  2.0234894 ]],\n",
       "\n",
       "       [[ 2.00875273, -4.94423177, -3.9765106 ],\n",
       "        [ 1.00875273,  3.05576823, -2.9765106 ],\n",
       "        [ 4.00875273, -0.94423177, -1.9765106 ],\n",
       "        ...,\n",
       "        [ 1.00875273, -2.94423177,  4.0234894 ],\n",
       "        [ 0.00875273,  2.05576823, -0.9765106 ],\n",
       "        [-0.99124727, -3.94423177, -3.9765106 ]],\n",
       "\n",
       "       [[ 4.00875273,  3.05576823,  4.0234894 ],\n",
       "        [-0.99124727,  2.05576823, -0.9765106 ],\n",
       "        [ 0.00875273,  2.05576823, -2.9765106 ],\n",
       "        ...,\n",
       "        [ 4.00875273,  1.05576823,  3.0234894 ],\n",
       "        [ 1.00875273,  3.05576823, -4.9765106 ],\n",
       "        [-3.99124727, -2.94423177, -4.9765106 ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-0.99124727, -3.94423177,  3.0234894 ],\n",
       "        [ 0.00875273,  1.05576823, -3.9765106 ],\n",
       "        [ 2.00875273,  4.05576823, -3.9765106 ],\n",
       "        ...,\n",
       "        [ 1.00875273, -4.94423177, -1.9765106 ],\n",
       "        [-1.99124727, -1.94423177,  0.0234894 ],\n",
       "        [-2.99124727,  2.05576823,  3.0234894 ]],\n",
       "\n",
       "       [[-1.99124727, -2.94423177, -0.9765106 ],\n",
       "        [-3.99124727,  0.05576823, -1.9765106 ],\n",
       "        [ 1.00875273, -1.94423177, -1.9765106 ],\n",
       "        ...,\n",
       "        [-2.99124727,  1.05576823, -3.9765106 ],\n",
       "        [-3.99124727,  3.05576823,  3.0234894 ],\n",
       "        [ 3.00875273,  3.05576823, -4.9765106 ]],\n",
       "\n",
       "       [[-4.99124727,  3.05576823, -2.9765106 ],\n",
       "        [ 4.00875273, -3.94423177, -1.9765106 ],\n",
       "        [ 4.00875273, -1.94423177,  3.0234894 ],\n",
       "        ...,\n",
       "        [-3.99124727, -4.94423177,  3.0234894 ],\n",
       "        [ 0.00875273, -2.94423177,  3.0234894 ],\n",
       "        [-3.99124727, -4.94423177,  3.0234894 ]]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dset5 + np.random.random(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/atatar/Documents/CIT/Teaching/UCG/DataScience/week1/Data/pokemon/dataset/Abra/2eb2a528f9a247358452b3c740df69a0.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [41], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m#add an image\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m pokemon \u001b[39m=\u001b[39m Image\u001b[39m.\u001b[39;49mopen(\u001b[39m'\u001b[39;49m\u001b[39m/home/atatar/Documents/CIT/Teaching/UCG/DataScience/week1/Data/pokemon/dataset/Abra/2eb2a528f9a247358452b3c740df69a0.jpg\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m      3\u001b[0m pokemon_arr \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(pokemon)\n\u001b[0;32m      4\u001b[0m f\u001b[39m.\u001b[39mcreate_dataset(\u001b[39m'\u001b[39m\u001b[39mpokemon\u001b[39m\u001b[39m'\u001b[39m,data\u001b[39m=\u001b[39mpokemon_arr)\n",
      "File \u001b[1;32mc:\\Users\\abahe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:3092\u001b[0m, in \u001b[0;36mopen\u001b[1;34m(fp, mode, formats)\u001b[0m\n\u001b[0;32m   3089\u001b[0m     filename \u001b[39m=\u001b[39m fp\n\u001b[0;32m   3091\u001b[0m \u001b[39mif\u001b[39;00m filename:\n\u001b[1;32m-> 3092\u001b[0m     fp \u001b[39m=\u001b[39m builtins\u001b[39m.\u001b[39;49mopen(filename, \u001b[39m\"\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m   3093\u001b[0m     exclusive_fp \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m   3095\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/atatar/Documents/CIT/Teaching/UCG/DataScience/week1/Data/pokemon/dataset/Abra/2eb2a528f9a247358452b3c740df69a0.jpg'"
     ]
    }
   ],
   "source": [
    "#add an image\n",
    "pokemon = Image.open('/home/atatar/Documents/CIT/Teaching/UCG/DataScience/week1/Data/pokemon/dataset/Abra/2eb2a528f9a247358452b3c740df69a0.jpg')\n",
    "pokemon_arr = np.array(pokemon)\n",
    "f.create_dataset('pokemon',data=pokemon_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Groups: Hiererchical Structure in HDF\n",
    "\n",
    " Storing all datasets as hf['dataset'] is similar to saving all your files in the same directory on your computer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = h5py.File('big_data.h5','r+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KeysViewHDF5 ['dataset1', 'dataset2', 'dataset3', 'dataset4', 'dataset5', 'empty_dataset']>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<HDF5 group \"/week1\" (0 members)>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.create_group('week1') #it is as if we have created a new folder called week1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<HDF5 group \"/week1/Data\" (0 members)>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#populate the folder week1\n",
    "w1 = f['week1']\n",
    "w1.create_dataset('dataset1',data=np.random.random(5))\n",
    "w1.create_dataset('dataset2',data=np.random.randint(-5,5,(10,10)))\n",
    "w1.create_group('Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<KeysViewHDF5 ['Data', 'dataset1', 'dataset2']>\n",
      "-----------\n",
      "<HDF5 group \"/week1\" (3 members)>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(w1.keys())\n",
    "print('-----------')\n",
    "print(w1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.95460048, 0.92717096, 0.93513563, 0.88954966, 0.59106595])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#access dataset1 in week1 using dictionary style\n",
    "f['week1']['dataset1'][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.95460048, 0.92717096, 0.93513563, 0.88954966, 0.59106595])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#access dataset1 in week1 using path style\n",
    "f['/week1/dataset1'][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attributes: Storing Metadata\n",
    "Attributes make files self-descripting. They work like dictionaries. They can store any kind of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = h5py.File('big_data.h5','r+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Attributes of HDF5 object at 2474412140528>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.attrs #attributes object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KeysViewHDF5 []>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.attrs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Attributes of HDF5 object at 2474407093536>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dset1 = f['dataset1']\n",
    "dset1.attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Unable to open object (object 'pokemon' doesn't exist)\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [57], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m pokemon \u001b[39m=\u001b[39m f[\u001b[39m'\u001b[39;49m\u001b[39mpokemon\u001b[39;49m\u001b[39m'\u001b[39;49m]\n\u001b[0;32m      2\u001b[0m pokemon\u001b[39m.\u001b[39mattrs[\u001b[39m'\u001b[39m\u001b[39mtitle\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mThis is a pokemon color image.\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m      3\u001b[0m pokemon\u001b[39m.\u001b[39mattrs[\u001b[39m'\u001b[39m\u001b[39msource\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mhttps://www.kaggle.com/datasets/vishalsubbiah/pokemon-images-and-types\u001b[39m\u001b[39m'\u001b[39m\n",
      "File \u001b[1;32mh5py\\_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mh5py\\_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\abahe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\h5py\\_hl\\group.py:328\u001b[0m, in \u001b[0;36mGroup.__getitem__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    326\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mInvalid HDF5 object reference\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    327\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(name, (\u001b[39mbytes\u001b[39m, \u001b[39mstr\u001b[39m)):\n\u001b[1;32m--> 328\u001b[0m     oid \u001b[39m=\u001b[39m h5o\u001b[39m.\u001b[39;49mopen(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mid, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_e(name), lapl\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_lapl)\n\u001b[0;32m    329\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    330\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mAccessing a group is done with bytes or str, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    331\u001b[0m                     \u001b[39m\"\u001b[39m\u001b[39m not \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mtype\u001b[39m(name)))\n",
      "File \u001b[1;32mh5py\\_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mh5py\\_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mh5py\\h5o.pyx:190\u001b[0m, in \u001b[0;36mh5py.h5o.open\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"Unable to open object (object 'pokemon' doesn't exist)\""
     ]
    }
   ],
   "source": [
    "pokemon = f['pokemon']\n",
    "pokemon.attrs['title'] = 'This is a pokemon color image.'\n",
    "pokemon.attrs['source'] = 'https://www.kaggle.com/datasets/vishalsubbiah/pokemon-images-and-types'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pokemon.attrs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in pokemon.attrs:\n",
    "    print(pokemon.attrs.get(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore an HDF5 File\n",
    "Download the Spectrometer data from the [link](https://ndownloader.figshare.com/files/7024271) into your working directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using a Viewer\n",
    "* https://support.hdfgroup.org/products/java/release/download.html\n",
    "* https://www.neonscience.org/resources/learning-hub/tutorials/setup-qgis-h5view"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] Unable to open file (unable to open file: name = 'NEONDSImagingSpectrometerData.h5', errno = 2, error message = 'No such file or directory', flags = 1, o_flags = 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [58], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m spectrometer \u001b[39m=\u001b[39m h5py\u001b[39m.\u001b[39;49mFile(\u001b[39m'\u001b[39;49m\u001b[39mNEONDSImagingSpectrometerData.h5\u001b[39;49m\u001b[39m'\u001b[39;49m,\u001b[39m'\u001b[39;49m\u001b[39mr+\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\abahe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\h5py\\_hl\\files.py:533\u001b[0m, in \u001b[0;36mFile.__init__\u001b[1;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, alignment_threshold, alignment_interval, **kwds)\u001b[0m\n\u001b[0;32m    525\u001b[0m     fapl \u001b[39m=\u001b[39m make_fapl(driver, libver, rdcc_nslots, rdcc_nbytes, rdcc_w0,\n\u001b[0;32m    526\u001b[0m                      locking, page_buf_size, min_meta_keep, min_raw_keep,\n\u001b[0;32m    527\u001b[0m                      alignment_threshold\u001b[39m=\u001b[39malignment_threshold,\n\u001b[0;32m    528\u001b[0m                      alignment_interval\u001b[39m=\u001b[39malignment_interval,\n\u001b[0;32m    529\u001b[0m                      \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    530\u001b[0m     fcpl \u001b[39m=\u001b[39m make_fcpl(track_order\u001b[39m=\u001b[39mtrack_order, fs_strategy\u001b[39m=\u001b[39mfs_strategy,\n\u001b[0;32m    531\u001b[0m                      fs_persist\u001b[39m=\u001b[39mfs_persist, fs_threshold\u001b[39m=\u001b[39mfs_threshold,\n\u001b[0;32m    532\u001b[0m                      fs_page_size\u001b[39m=\u001b[39mfs_page_size)\n\u001b[1;32m--> 533\u001b[0m     fid \u001b[39m=\u001b[39m make_fid(name, mode, userblock_size, fapl, fcpl, swmr\u001b[39m=\u001b[39;49mswmr)\n\u001b[0;32m    535\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(libver, \u001b[39mtuple\u001b[39m):\n\u001b[0;32m    536\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_libver \u001b[39m=\u001b[39m libver\n",
      "File \u001b[1;32mc:\\Users\\abahe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\h5py\\_hl\\files.py:228\u001b[0m, in \u001b[0;36mmake_fid\u001b[1;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[0;32m    226\u001b[0m     fid \u001b[39m=\u001b[39m h5f\u001b[39m.\u001b[39mopen(name, flags, fapl\u001b[39m=\u001b[39mfapl)\n\u001b[0;32m    227\u001b[0m \u001b[39melif\u001b[39;00m mode \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mr+\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m--> 228\u001b[0m     fid \u001b[39m=\u001b[39m h5f\u001b[39m.\u001b[39;49mopen(name, h5f\u001b[39m.\u001b[39;49mACC_RDWR, fapl\u001b[39m=\u001b[39;49mfapl)\n\u001b[0;32m    229\u001b[0m \u001b[39melif\u001b[39;00m mode \u001b[39min\u001b[39;00m [\u001b[39m'\u001b[39m\u001b[39mw-\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mx\u001b[39m\u001b[39m'\u001b[39m]:\n\u001b[0;32m    230\u001b[0m     fid \u001b[39m=\u001b[39m h5f\u001b[39m.\u001b[39mcreate(name, h5f\u001b[39m.\u001b[39mACC_EXCL, fapl\u001b[39m=\u001b[39mfapl, fcpl\u001b[39m=\u001b[39mfcpl)\n",
      "File \u001b[1;32mh5py\\_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mh5py\\_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mh5py\\h5f.pyx:106\u001b[0m, in \u001b[0;36mh5py.h5f.open\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] Unable to open file (unable to open file: name = 'NEONDSImagingSpectrometerData.h5', errno = 2, error message = 'No such file or directory', flags = 1, o_flags = 2)"
     ]
    }
   ],
   "source": [
    "spectrometer = h5py.File('NEONDSImagingSpectrometerData.h5','r+')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dictionary Style Iteration\n",
    "Iterate over the keys at every layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in spectrometer:\n",
    "    print('Key:',k)\n",
    "    print('Value:',spectrometer[k]) #hdf5 object: group or dataset\n",
    "    print('---------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = []\n",
    "datasets = []\n",
    "\n",
    "for k,v in spectrometer.items():\n",
    "    if isinstance(v, h5py.Dataset):\n",
    "        print('Type: Dataset')\n",
    "        print(v.name)\n",
    "        print(v.shape)\n",
    "        print(v.ndim)\n",
    "        print(v.nbytes)\n",
    "        print(v.dtype)\n",
    "        datasets.append(v)\n",
    "    if isinstance(v, h5py.Group):\n",
    "        print('Type: Group')\n",
    "        print(v.name)\n",
    "        print('number of members:', len(v.keys()))\n",
    "        groups.append(v)\n",
    "    print('-----------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#access one of the datasets at layer 0\n",
    "reflectance = spectrometer['Reflectance']\n",
    "reflectance[:,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#explore some attributes\n",
    "spectrometer.attrs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectrometer.attrs.get('SITE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#see all the attributes\n",
    "for k in spectrometer.attrs:\n",
    "    print(spectrometer.attrs[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#see all the attributes\n",
    "for k in spectrometer.attrs.values():\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in spectrometer.attrs.items():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#access a dataset in layer 1\n",
    "spectrometer['spatialInfo/']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a random dataset under spatialInfo\n",
    "arr = np.random.randint(-5,5,(10,10))\n",
    "spectrometer['spatialInfo'].create_dataset('random',data=arr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add attributes\n",
    "spectrometer['/spatialInfo/random'].attrs['Description'] = 'Random numpy array of integers between -5 and 5.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = []\n",
    "datasets = []\n",
    "\n",
    "for k,v in spectrometer.items():\n",
    "    if isinstance(v, h5py.Dataset):\n",
    "        print('Type: Dataset')\n",
    "        print(v.name)\n",
    "        print(v.shape)\n",
    "        print(v.ndim)\n",
    "        print(v.nbytes)\n",
    "        print(v.dtype)\n",
    "        datasets.append(v)\n",
    "    if isinstance(v, h5py.Group):\n",
    "        print('Type: Group')\n",
    "        print(v.name)\n",
    "        print('number of members:', len(v.keys()))\n",
    "        groups.append(v)\n",
    "    print('-----------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cannot find the random dataset.\n",
    "datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multilayer Iteration\n",
    "\n",
    "We cover all layers at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ls_nodes(node):\n",
    "    print(node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectrometer.visit(ls_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ls_nodes(node):\n",
    "    print(spectrometer[node])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectrometer.visit(ls_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's get fancy\n",
    "spectrometer.visit(lambda x: print(spectrometer[x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectrometer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "917f1fe2c395e695a2acad0b272f87ed7c0aa19cfb0add5bf0124b7c8be35a9d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
